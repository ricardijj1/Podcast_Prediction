{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Podcast_Name</th>\n",
       "      <th>Episode_Title</th>\n",
       "      <th>Episode_Length_minutes</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Host_Popularity_percentage</th>\n",
       "      <th>Publication_Day</th>\n",
       "      <th>Publication_Time</th>\n",
       "      <th>Guest_Popularity_percentage</th>\n",
       "      <th>Number_of_Ads</th>\n",
       "      <th>Episode_Sentiment</th>\n",
       "      <th>Listening_Time_minutes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Mystery Matters</td>\n",
       "      <td>Episode 98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True Crime</td>\n",
       "      <td>74.81</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>Night</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>31.41998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Joke Junction</td>\n",
       "      <td>Episode 26</td>\n",
       "      <td>119.80</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>66.95</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>Afternoon</td>\n",
       "      <td>75.95</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Negative</td>\n",
       "      <td>88.01241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Study Sessions</td>\n",
       "      <td>Episode 16</td>\n",
       "      <td>73.90</td>\n",
       "      <td>Education</td>\n",
       "      <td>69.97</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Evening</td>\n",
       "      <td>8.97</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Negative</td>\n",
       "      <td>44.92531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Digital Digest</td>\n",
       "      <td>Episode 45</td>\n",
       "      <td>67.17</td>\n",
       "      <td>Technology</td>\n",
       "      <td>57.22</td>\n",
       "      <td>Monday</td>\n",
       "      <td>Morning</td>\n",
       "      <td>78.70</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>46.27824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Mind &amp; Body</td>\n",
       "      <td>Episode 86</td>\n",
       "      <td>110.51</td>\n",
       "      <td>Health</td>\n",
       "      <td>80.07</td>\n",
       "      <td>Monday</td>\n",
       "      <td>Afternoon</td>\n",
       "      <td>58.68</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>75.61031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id     Podcast_Name Episode_Title  Episode_Length_minutes       Genre  \\\n",
       "0   0  Mystery Matters    Episode 98                     NaN  True Crime   \n",
       "1   1    Joke Junction    Episode 26                  119.80      Comedy   \n",
       "2   2   Study Sessions    Episode 16                   73.90   Education   \n",
       "3   3   Digital Digest    Episode 45                   67.17  Technology   \n",
       "4   4      Mind & Body    Episode 86                  110.51      Health   \n",
       "\n",
       "   Host_Popularity_percentage Publication_Day Publication_Time  \\\n",
       "0                       74.81        Thursday            Night   \n",
       "1                       66.95        Saturday        Afternoon   \n",
       "2                       69.97         Tuesday          Evening   \n",
       "3                       57.22          Monday          Morning   \n",
       "4                       80.07          Monday        Afternoon   \n",
       "\n",
       "   Guest_Popularity_percentage  Number_of_Ads Episode_Sentiment  \\\n",
       "0                          NaN            0.0          Positive   \n",
       "1                        75.95            2.0          Negative   \n",
       "2                         8.97            0.0          Negative   \n",
       "3                        78.70            2.0          Positive   \n",
       "4                        58.68            3.0           Neutral   \n",
       "\n",
       "   Listening_Time_minutes  \n",
       "0                31.41998  \n",
       "1                88.01241  \n",
       "2                44.92531  \n",
       "3                46.27824  \n",
       "4                75.61031  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load train dataset csv\n",
    "df_train = pd.read_csv(\"/Users/sa21/Desktop/Podcast_Prediction/Data/raw/train.csv\")\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'Podcast_Name', 'Episode_Title', 'Episode_Length_minutes',\n",
       "       'Genre', 'Host_Popularity_percentage', 'Publication_Day',\n",
       "       'Publication_Time', 'Guest_Popularity_percentage', 'Number_of_Ads',\n",
       "       'Episode_Sentiment', 'Listening_Time_minutes'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#columns names\n",
    "colum_names = df_train.columns\n",
    "colum_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this EDA, we learned that episode length, ad count, and sentiment have outliers and skewness that may require scaling or transformation before modeling. The group-based median imputation approach helped retain important information without distorting the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                             0\n",
       "Podcast_Name                   0\n",
       "Episode_Title                  0\n",
       "Episode_Length_minutes         0\n",
       "Genre                          0\n",
       "Host_Popularity_percentage     0\n",
       "Publication_Day                0\n",
       "Publication_Time               0\n",
       "Guest_Popularity_percentage    0\n",
       "Number_of_Ads                  0\n",
       "Episode_Sentiment              0\n",
       "Listening_Time_minutes         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Impute missing values within each podcast group using the median\n",
    "# handling missing values for Episode_Length_minutes\n",
    "df_train['Episode_Length_minutes'] = df_train.groupby('Podcast_Name')['Episode_Length_minutes'].transform(lambda x: x.fillna(x.median()))\n",
    "# handling missing values for Guest_Popularity_percentage\n",
    "df_train['Guest_Popularity_percentage'] = df_train.groupby('Podcast_Name')['Guest_Popularity_percentage'].transform(lambda x: x.fillna(x.median()))\n",
    "# handling missing values for Number_of_Ads\n",
    "df_train['Number_of_Ads'] = df_train.groupby('Podcast_Name')['Number_of_Ads'].transform(lambda x: x.fillna(x.median()))\n",
    "# Check that all missing values have been handled\n",
    "df_train.isnull().sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical sentiment labels to numeric values for modeling\n",
    "# Negative = -1, Neutral = 0, Positive = 1\n",
    "sentiment_map = {'Negative': -1, 'Neutral': 0, 'Positive': 1}\n",
    "df_train['Episode_Sentiment'] = df_train['Episode_Sentiment'].map(sentiment_map)\n",
    "\n",
    "# Then one-hot encode only other categoricals:\n",
    "df_train = pd.get_dummies(df_train, columns=['Genre', 'Publication_Day','Publication_Time'])\n",
    "\n",
    "df_train = df_train.astype({col: int for col in df_train.select_dtypes(['bool']).columns})\n",
    "\n",
    "final_df = df_train.drop(columns=['Episode_Title', 'Podcast_Name'], errors='ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save clean data in new csv \n",
    "final_df.to_csv('/Users/sa21/Desktop/Podcast_Prediction/Data/processed/df_train_cleaned.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
