{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Podcast_Name</th>\n",
       "      <th>Episode_Title</th>\n",
       "      <th>Episode_Length_minutes</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Host_Popularity_percentage</th>\n",
       "      <th>Publication_Day</th>\n",
       "      <th>Publication_Time</th>\n",
       "      <th>Guest_Popularity_percentage</th>\n",
       "      <th>Number_of_Ads</th>\n",
       "      <th>Episode_Sentiment</th>\n",
       "      <th>Listening_Time_minutes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Mystery Matters</td>\n",
       "      <td>Episode 98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True Crime</td>\n",
       "      <td>74.81</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>Night</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>31.41998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Joke Junction</td>\n",
       "      <td>Episode 26</td>\n",
       "      <td>119.80</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>66.95</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>Afternoon</td>\n",
       "      <td>75.95</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Negative</td>\n",
       "      <td>88.01241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Study Sessions</td>\n",
       "      <td>Episode 16</td>\n",
       "      <td>73.90</td>\n",
       "      <td>Education</td>\n",
       "      <td>69.97</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Evening</td>\n",
       "      <td>8.97</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Negative</td>\n",
       "      <td>44.92531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Digital Digest</td>\n",
       "      <td>Episode 45</td>\n",
       "      <td>67.17</td>\n",
       "      <td>Technology</td>\n",
       "      <td>57.22</td>\n",
       "      <td>Monday</td>\n",
       "      <td>Morning</td>\n",
       "      <td>78.70</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>46.27824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Mind &amp; Body</td>\n",
       "      <td>Episode 86</td>\n",
       "      <td>110.51</td>\n",
       "      <td>Health</td>\n",
       "      <td>80.07</td>\n",
       "      <td>Monday</td>\n",
       "      <td>Afternoon</td>\n",
       "      <td>58.68</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>75.61031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id     Podcast_Name Episode_Title  Episode_Length_minutes       Genre  \\\n",
       "0   0  Mystery Matters    Episode 98                     NaN  True Crime   \n",
       "1   1    Joke Junction    Episode 26                  119.80      Comedy   \n",
       "2   2   Study Sessions    Episode 16                   73.90   Education   \n",
       "3   3   Digital Digest    Episode 45                   67.17  Technology   \n",
       "4   4      Mind & Body    Episode 86                  110.51      Health   \n",
       "\n",
       "   Host_Popularity_percentage Publication_Day Publication_Time  \\\n",
       "0                       74.81        Thursday            Night   \n",
       "1                       66.95        Saturday        Afternoon   \n",
       "2                       69.97         Tuesday          Evening   \n",
       "3                       57.22          Monday          Morning   \n",
       "4                       80.07          Monday        Afternoon   \n",
       "\n",
       "   Guest_Popularity_percentage  Number_of_Ads Episode_Sentiment  \\\n",
       "0                          NaN            0.0          Positive   \n",
       "1                        75.95            2.0          Negative   \n",
       "2                         8.97            0.0          Negative   \n",
       "3                        78.70            2.0          Positive   \n",
       "4                        58.68            3.0           Neutral   \n",
       "\n",
       "   Listening_Time_minutes  \n",
       "0                31.41998  \n",
       "1                88.01241  \n",
       "2                44.92531  \n",
       "3                46.27824  \n",
       "4                75.61031  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load train dataset csv\n",
    "df_train = pd.read_csv(\"/Users/sa21/Desktop/Podcast_Prediction/Data/raw/train.csv\")\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'Podcast_Name', 'Episode_Title', 'Episode_Length_minutes',\n",
       "       'Genre', 'Host_Popularity_percentage', 'Publication_Day',\n",
       "       'Publication_Time', 'Guest_Popularity_percentage', 'Number_of_Ads',\n",
       "       'Episode_Sentiment', 'Listening_Time_minutes'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#columns names\n",
    "colum_names = df_train.columns\n",
    "colum_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this EDA, we learned that episode length, ad count, and sentiment have outliers and skewness that may require scaling or transformation before modeling. The group-based median imputation approach helped retain important information without distorting the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                             0\n",
       "Podcast_Name                   0\n",
       "Episode_Title                  0\n",
       "Episode_Length_minutes         0\n",
       "Genre                          0\n",
       "Host_Popularity_percentage     0\n",
       "Publication_Day                0\n",
       "Publication_Time               0\n",
       "Guest_Popularity_percentage    0\n",
       "Number_of_Ads                  0\n",
       "Episode_Sentiment              0\n",
       "Listening_Time_minutes         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Impute missing values within each podcast group using the median\n",
    "# handling missing values for Episode_Length_minutes\n",
    "df_train['Episode_Length_minutes'] = df_train.groupby('Podcast_Name')['Episode_Length_minutes'].transform(lambda x: x.fillna(x.median()))\n",
    "# handling missing values for Guest_Popularity_percentage\n",
    "df_train['Guest_Popularity_percentage'] = df_train.groupby('Podcast_Name')['Guest_Popularity_percentage'].transform(lambda x: x.fillna(x.median()))\n",
    "# handling missing values for Number_of_Ads\n",
    "df_train['Number_of_Ads'] = df_train.groupby('Podcast_Name')['Number_of_Ads'].transform(lambda x: x.fillna(x.median()))\n",
    "# Check that all missing values have been handled\n",
    "df_train.isnull().sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical sentiment labels to numeric values for modeling\n",
    "# Negative = -1, Neutral = 0, Positive = 1\n",
    "sentiment_map = {'Negative': -1, 'Neutral': 0, 'Positive': 1}\n",
    "df_train['Episode_Sentiment'] = df_train['Episode_Sentiment'].map(sentiment_map)\n",
    "\n",
    "# Then one-hot encode only other categoricals:\n",
    "df_train = pd.get_dummies(df_train, columns=['Genre', 'Publication_Day','Publication_Time'])\n",
    "\n",
    "df_train = df_train.astype({col: int for col in df_train.select_dtypes(['bool']).columns})\n",
    "\n",
    "final_df = df_train.drop(columns=['Episode_Title', 'Podcast_Name'], errors='ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save clean data in new csv \n",
    "final_df.to_csv('/Users/sa21/Desktop/Podcast_Prediction/Data/processed/df_train_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Podcast_Name</th>\n",
       "      <th>Episode_Title</th>\n",
       "      <th>Episode_Length_minutes</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Host_Popularity_percentage</th>\n",
       "      <th>Publication_Day</th>\n",
       "      <th>Publication_Time</th>\n",
       "      <th>Guest_Popularity_percentage</th>\n",
       "      <th>Number_of_Ads</th>\n",
       "      <th>Episode_Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>750000</td>\n",
       "      <td>Educational Nuggets</td>\n",
       "      <td>Episode 73</td>\n",
       "      <td>78.96</td>\n",
       "      <td>Education</td>\n",
       "      <td>38.11</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>Evening</td>\n",
       "      <td>53.33</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>750001</td>\n",
       "      <td>Sound Waves</td>\n",
       "      <td>Episode 23</td>\n",
       "      <td>27.87</td>\n",
       "      <td>Music</td>\n",
       "      <td>71.29</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>Morning</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>750002</td>\n",
       "      <td>Joke Junction</td>\n",
       "      <td>Episode 11</td>\n",
       "      <td>69.10</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>67.89</td>\n",
       "      <td>Friday</td>\n",
       "      <td>Evening</td>\n",
       "      <td>97.51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>750003</td>\n",
       "      <td>Comedy Corner</td>\n",
       "      <td>Episode 73</td>\n",
       "      <td>115.39</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>23.40</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>Morning</td>\n",
       "      <td>51.75</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>750004</td>\n",
       "      <td>Life Lessons</td>\n",
       "      <td>Episode 50</td>\n",
       "      <td>72.32</td>\n",
       "      <td>Lifestyle</td>\n",
       "      <td>58.10</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>Morning</td>\n",
       "      <td>11.30</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id         Podcast_Name Episode_Title  Episode_Length_minutes  \\\n",
       "0  750000  Educational Nuggets    Episode 73                   78.96   \n",
       "1  750001          Sound Waves    Episode 23                   27.87   \n",
       "2  750002        Joke Junction    Episode 11                   69.10   \n",
       "3  750003        Comedy Corner    Episode 73                  115.39   \n",
       "4  750004         Life Lessons    Episode 50                   72.32   \n",
       "\n",
       "       Genre  Host_Popularity_percentage Publication_Day Publication_Time  \\\n",
       "0  Education                       38.11        Saturday          Evening   \n",
       "1      Music                       71.29          Sunday          Morning   \n",
       "2     Comedy                       67.89          Friday          Evening   \n",
       "3     Comedy                       23.40          Sunday          Morning   \n",
       "4  Lifestyle                       58.10       Wednesday          Morning   \n",
       "\n",
       "   Guest_Popularity_percentage  Number_of_Ads Episode_Sentiment  \n",
       "0                        53.33            1.0           Neutral  \n",
       "1                          NaN            0.0           Neutral  \n",
       "2                        97.51            0.0          Positive  \n",
       "3                        51.75            2.0          Positive  \n",
       "4                        11.30            2.0           Neutral  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load test dataset csv\n",
    "df_test = pd.read_csv(\"/Users/sa21/Desktop/Podcast_Prediction/Data/raw/test.csv\")\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                             0\n",
       "Podcast_Name                   0\n",
       "Episode_Title                  0\n",
       "Episode_Length_minutes         0\n",
       "Genre                          0\n",
       "Host_Popularity_percentage     0\n",
       "Publication_Day                0\n",
       "Publication_Time               0\n",
       "Guest_Popularity_percentage    0\n",
       "Number_of_Ads                  0\n",
       "Episode_Sentiment              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Impute missing values within each podcast group using the median\n",
    "# handling missing values for Episode_Length_minutes\n",
    "df_test['Episode_Length_minutes'] = df_test.groupby('Podcast_Name')['Episode_Length_minutes'].transform(lambda x: x.fillna(x.median()))\n",
    "# handling missing values for Guest_Popularity_percentage\n",
    "df_test['Guest_Popularity_percentage'] = df_test.groupby('Podcast_Name')['Guest_Popularity_percentage'].transform(lambda x: x.fillna(x.median()))\n",
    "# handling missing values for Number_of_Ads\n",
    "df_test['Number_of_Ads'] = df_test.groupby('Podcast_Name')['Number_of_Ads'].transform(lambda x: x.fillna(x.median()))\n",
    "# Check that all missing values have been handled\n",
    "df_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical sentiment labels to numeric values for modeling\n",
    "# Negative = -1, Neutral = 0, Positive = 1\n",
    "sentiment_map = {'Negative': -1, 'Neutral': 0, 'Positive': 1}\n",
    "df_test['Episode_Sentiment'] = df_test['Episode_Sentiment'].map(sentiment_map)\n",
    "\n",
    "# Then one-hot encode only other categoricals:\n",
    "df_test = pd.get_dummies(df_test, columns=['Genre', 'Publication_Day', 'Publication_Time'])\n",
    "\n",
    "# Convert boolean columns to integers\n",
    "df_test = df_test.astype({col: int for col in df_test.select_dtypes(['bool']).columns})\n",
    "\n",
    "# Drop non-numeric or irrelevant columns\n",
    "final_test_df = df_test.drop(columns=['Episode_Title', 'Podcast_Name'], errors='ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save clean data in new csv \n",
    "final_test_df.to_csv('/Users/sa21/Desktop/Podcast_Prediction/Data/processed/df_test_cleaned.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
